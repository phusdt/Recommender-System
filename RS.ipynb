{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRwxZSrFLlFx",
    "outputId": "a0b2f808-2e1b-48bd-d2c8-34bd3058e272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXNrBtuXOMYO",
    "outputId": "f1078d9e-1121-4691-98bb-6c8d1234edc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/Colab Notebooks/RBM - CF/Recommender-System\n"
     ]
    }
   ],
   "source": [
    "cd /content/gdrive/MyDrive/Colab Notebooks/RBM - CF/Recommender-System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tUu9p3FwLVjf"
   },
   "outputs": [],
   "source": [
    "from collaborative_filtering import CF \n",
    "from demographic_filtering import DF\n",
    "from perceptron import Perceptron as pct\n",
    "from get_data import (\n",
    "    get_users_data,\n",
    "    get_rating_base_data,\n",
    "    get_rating_test_data,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Import RBM model script\n",
    "from rbm import RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "wiTTPttzLO_G",
    "outputId": "a06f24ac-9350-4785-b9b8-8789e9352d5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Weights and Biases\n",
    "import wandb\n",
    "wandb.init(entity=\"phusdt\", project=\"boltzmann_machines_collaborative_filtering\")\n",
    "\n",
    "# Config is a variable that holds and saves hyper-parameters\n",
    "config = wandb.config  # Initialize config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYFL8LqNLVji",
    "outputId": "2e78f478-a611-4d69-f5d6-a74cdc678b28"
   },
   "outputs": [],
   "source": [
    "# CF \n",
    "RATE_TRAIN = get_rating_base_data().values # convert to matrix\n",
    "RATE_TEST = get_rating_test_data().values # convert to matrix\n",
    "\n",
    "RATE_TRAIN[:, :2] -= 1 # start from 0\n",
    "RATE_TEST[:, :2] -= 1\n",
    "\n",
    "CF = CF(RATE_TRAIN, k=25)\n",
    "CF.fit()\n",
    "\n",
    "print('Similar Matrix Works')\n",
    "print(CF.S)\n",
    "print('Number of rows: ', CF.S.shape[0])\n",
    "print('Number of columns: ', CF.S.shape[1])\n",
    "\n",
    "ids = np.where(RATE_TEST[:, 0] == 0)[0].astype('int32')\n",
    "real_items_1 = RATE_TEST[(np.where((RATE_TEST[:, 0] == 0) & (RATE_TEST[:, 2] >= 3)))]\n",
    "predicted_items = []\n",
    "\n",
    "for row in RATE_TEST[ids, :]:\n",
    "    predicted_rating = CF.pred(0, row[1])\n",
    "    if predicted_rating >= 3:\n",
    "        predicted_items.append(row[1])\n",
    "\n",
    "print('Items which user 1 actually like: ', real_items_1[:, 1])\n",
    "print('Items in prediction which user 1 might like ', predicted_items)\n",
    "\n",
    "\n",
    "n_test = RATE_TEST.shape[0]\n",
    "correct_items_count = 0\n",
    "real_items_user_like_count = len(np.where(RATE_TEST[:, 2] >= 3)[0].astype(np.int32))\n",
    "\n",
    "user_id = 0\n",
    "while user_id < CF.n_users:\n",
    "    ids = np.where(RATE_TEST[:, 0] == user_id)[0].astype('int32')\n",
    "    real_items = RATE_TEST[(np.where((RATE_TEST[:, 0] == user_id) & (RATE_TEST[:, 2] >= 3)))]\n",
    "    for row in RATE_TEST[ids, :]:\n",
    "        predicted_rating = CF.pred(user_id, row[1])\n",
    "        if predicted_rating >= 3 and row[1] in real_items:\n",
    "            correct_items_count += 1\n",
    "    user_id += 1\n",
    "accuracy = correct_items_count/real_items_user_like_count\n",
    "print('The accuracy of Collaborative Filtering: {0}/{1} = {2}'.format(correct_items_count, real_items_user_like_count, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCdP03aiOI6E",
    "outputId": "98c32808-b157-4f4e-c92a-07d83ea5ebe0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "x = list(set(get_rating_base_data().iloc[:,1]))\n",
    "x = pd.DataFrame(columns=x)\n",
    "# lấy dữ liệu của những iteam thực sự được người dùng thích\n",
    "zipper = np.ones(len(real_items_1[:, 1]))\n",
    "dict_ = dict(zip(real_items_1[:, 1], zipper))\n",
    "y_real = x.append(dict_,ignore_index=True).fillna(0).values\n",
    "\n",
    "# lấy dữ liệu của những item predict\n",
    "zipper = np.ones(len(predicted_items))\n",
    "dict_ = dict(zip(predicted_items, zipper))\n",
    "y_pred = x.append(dict_,ignore_index=True).fillna(0).values\n",
    "\n",
    "recall = recall_score(y_real, y_pred, average='macro')\n",
    "precision = precision_score(y_real, y_pred, average='macro')\n",
    "\n",
    "print('Chỉ số recall: {}\\nChỉ số precision: {}'.format(recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLL13qSSLVjk",
    "outputId": "b9411f61-2006-4b37-8768-be8505028076"
   },
   "outputs": [],
   "source": [
    "# DF\n",
    "RATE_TRAIN = get_rating_base_data().values # convert to matrix\n",
    "RATE_TEST = get_rating_test_data().values # convert to matrix\n",
    "\n",
    "RATE_TRAIN[:, :2] -= 1 # start from 0\n",
    "RATE_TEST[:, :2] -= 1\n",
    "USERS = get_users_data()\n",
    "DF = DF(USERS, RATE_TRAIN, 25)\n",
    "DF.fit()\n",
    "\n",
    "print(\"Ma trận tương đồng thông tin\")\n",
    "print(DF.similarities)\n",
    "print(\"Số hàng của ma trận:\", DF.similarities.shape[0])\n",
    "print(\"Số cột của ma trận: \", DF.similarities.shape[1])\n",
    "\n",
    "ids = np.where(RATE_TEST[:, 0] == 0)[0].astype(\"int32\")\n",
    "real_items_1 = RATE_TEST[(np.where((RATE_TEST[:, 0] == 0) & (RATE_TEST[:, 2] >= 3)))]\n",
    "correct_predicted_items = []\n",
    "\n",
    "for row in RATE_TEST[ids, :]:\n",
    "    predicted_rating = DF.pred(0, row[1])\n",
    "    if predicted_rating >= 3 and row[1] in real_items_1:\n",
    "        correct_predicted_items.append(row[1])\n",
    "\n",
    "\n",
    "print(\"Những items user 1 thật sự thích       : \", real_items_1[:, 1])\n",
    "print(\"Những items user 1 được dự đoán thích  : \", correct_predicted_items)\n",
    "\n",
    "n_test = RATE_TEST.shape[0]\n",
    "correct_items_count = 0\n",
    "real_items_user_like_count = len(np.where(RATE_TEST[:, 2] >= 3)[0].astype(np.int32))\n",
    "\n",
    "user_id = 0\n",
    "while user_id < DF.n_users:\n",
    "    ids = np.where(RATE_TEST[:, 0] == user_id)[0].astype(\"int32\")\n",
    "    real_items = RATE_TEST[(np.where((RATE_TEST[:, 0] == user_id) & (RATE_TEST[:, 2] >= 3)))]\n",
    "    for row in RATE_TEST[ids, :]:\n",
    "        predicted_rating = DF.pred(user_id, row[1])\n",
    "        if predicted_rating >= 3 and row[1] in real_items:\n",
    "            correct_items_count = correct_items_count + 1\n",
    "    user_id = user_id + 1\n",
    "\n",
    "print(\"Độ chính xác của Demographic Filtering :\", correct_items_count / real_items_user_like_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzEtiIiMLVjx"
   },
   "outputs": [],
   "source": [
    "# # Perceptron\n",
    "# ids = np.where(RATE_TEST[:, 0] == 0)[0].astype(\"int32\")\n",
    "\n",
    "# MATRIX_DF = []\n",
    "# MATRIX_CF = []\n",
    "\n",
    "# for row in RATE_TEST[ids, :]:\n",
    "#     p_cf = CF.pred(0, row[1])\n",
    "#     p_df = DF.pred(u=0, i=row[2])\n",
    "#     MATRIX_CF.append([0, row[1], p_cf])\n",
    "#     MATRIX_DF.append([0, row[1], p_df])\n",
    "# MATRIX_CF = np.asarray(MATRIX_CF)\n",
    "# MATRIX_DF = np.asarray(MATRIX_DF)\n",
    "\n",
    "# CF_predicted = np.asanyarray(MATRIX_CF[:, 2])\n",
    "# DF_predicted = MATRIX_DF[:, 2]\n",
    "# true_rating = RATE_TEST[ids, 2]\n",
    "\n",
    "# dataset = np.c_[CF_predicted, DF_predicted, true_rating]\n",
    "\n",
    "# # print(\"Ma trận dự đoán đánh giá CF, DF, True Rating\")\n",
    "# # print(dataset)\n",
    "\n",
    "# PLA = Perceptron(dataset, 0.003, len(ids))\n",
    "# PLA.fit()\n",
    "# predicted_ratings_pla = PLA.predict()\n",
    "\n",
    "# print(\"Dự đoán đánh giá sau khi được điều chỉnh\")\n",
    "# print(np.round(predicted_ratings_pla, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQf1vhyMLVj4"
   },
   "outputs": [],
   "source": [
    "ratings = get_rating_base_data()\n",
    "df_train = pd.pivot_table(ratings, values='rating', index=['user_id'],\n",
    "                    columns=['item_id'], aggfunc=np.mean).fillna(0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "416_fHPBjK-9"
   },
   "outputs": [],
   "source": [
    "# mapping:\n",
    "#   - rating > 3 : 1 \n",
    "#   - 0 < rating < 3: 0\n",
    "#   - rating = 0 : -1\n",
    "cond = lambda x: 1 if x >= 3 else (-1 if x == 0 else 0)\n",
    "df_train = df_train.applymap(cond) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gY7_i3JT7SvS"
   },
   "outputs": [],
   "source": [
    "# Split the ratings data frame into 75% training and 25% testing\n",
    "trainingset, testset = train_test_split(ratings, train_size=0.75)\n",
    "\n",
    "# Convert training and test data into Numpy arrays\n",
    "trainingset = np.array(trainingset, dtype='int')\n",
    "testset = np.array(testset, dtype='int')\n",
    "\n",
    "# Collect the total number of movies and users in order to then make a matrix of the data\n",
    "config.nb_users = int(max(max(trainingset[:, 0]), max(testset[:, 0])))\n",
    "config.nb_movies = int(max(max(trainingset[:, 1]), max(testset[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "impa_2VdOVeB"
   },
   "outputs": [],
   "source": [
    "# Function to convert the data into an array with users in lines and movies in columns\n",
    "def convert(data):\n",
    "    new_data = []  # initialise list\n",
    "    for id_users in range(1, config.nb_users + 1):\n",
    "        id_movies = data[:, 1][data[:, 0] == id_users]\n",
    "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
    "        ratings = np.zeros(config.nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "\n",
    "\n",
    "# Convert training and test sets into arrays\n",
    "trainingset = convert(trainingset)\n",
    "testset = convert(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09Nwm6UaOafx"
   },
   "outputs": [],
   "source": [
    "# Convert training and test sets into torch sensors\n",
    "training_set = torch.FloatTensor(trainingset)\n",
    "test_set = torch.FloatTensor(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLTTXay2Qal6"
   },
   "outputs": [],
   "source": [
    "# Number of users\n",
    "config.nb_users = DF.n_users\n",
    "# Number of items\n",
    "config.nb_items = DF.n_items\n",
    "# Number of movies is the number of visible units\n",
    "config.n_vis = len(training_set[0])\n",
    "# This tunable parameter is the number of features that we want to detect (number of hidden units)\n",
    "config.n_hid = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nh6OueAPSqqy",
    "outputId": "4de4ce38-d904-4307-c41b-6780e1670bc6"
   },
   "outputs": [],
   "source": [
    "# Create the model object RBM()\n",
    "rbm = RBM(config.n_vis, config.n_hid)\n",
    "\n",
    "config.batch_size_ = 512  # set batch size to be 512 (tunable)\n",
    "reconerr = []  # keep track of reconstruction error\n",
    "config.nb_epoch = 50  # run for 50 epochs\n",
    "\n",
    "# RMSE\n",
    "rmse = []\n",
    "\n",
    "# Train the RBM\n",
    "# First for loop - go through every single epoch\n",
    "for epoch in range(1, config.nb_epoch + 1):\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0.  # a counter (float type)\n",
    "\n",
    "    # Second for loop - go through every single user\n",
    "    # Lower bound is 0, upper bound is (nb_users - batch_size_), batch_size_ is the step of each batch (512)\n",
    "    # The 1st batch is for user with ID = 0 to user with ID = 511\n",
    "    for id_user in range(0, config.nb_users - config.batch_size_, config.batch_size_):\n",
    "\n",
    "        # At the beginning, v0 = vk. Then we update vk\n",
    "        vk = training_set[id_user:id_user + config.batch_size_]\n",
    "        v0 = training_set[id_user:id_user + config.batch_size_]\n",
    "        ph0, _ = rbm.sample_h(v0)\n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "        # Calculate the loss using contrastive divergence\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "\n",
    "        # Compare vk updated after the training to v0 (the target)\n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 >= 0] - vk[v0 >= 0])**2))\n",
    "        s += 1.\n",
    "\n",
    "    # Update RMSE reconstruction error\n",
    "    reconerr.append(train_recon_error / s)\n",
    "\n",
    "    print('Epoch: ' + str(epoch) + '- RMSE Reconstruction Error: ' + str(train_recon_error.data.numpy() / s))\n",
    "    wandb.log({\"Train RMSE\": train_recon_error.data.numpy() / s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jBf8mPgt05-",
    "outputId": "0cb36f51-5c89-4f2e-ab1a-018b7ff6f8e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7093, 0.8605, 0.2075, 0.1905, 0.4305, 0.3963, 0.5160, 0.0270, 0.7015,\n",
       "         0.7043, 0.1175, 0.2774, 0.5912, 0.8797, 0.1555, 0.3118, 0.1021, 0.1235,\n",
       "         0.3839, 0.0044, 0.1565, 0.4884, 0.5836, 0.6928, 0.7131, 0.1555, 0.4190,\n",
       "         0.0509, 0.1111, 0.1319, 0.8891, 0.8353, 0.0730, 0.0373, 0.3155, 0.9898,\n",
       "         0.3819, 0.8308, 0.1921, 0.7566, 0.8650, 0.5129, 0.3271, 0.6680, 0.4904,\n",
       "         0.0596, 0.5981, 0.4602, 0.4618, 0.6667, 0.9513, 0.2119, 0.7331, 0.9846,\n",
       "         0.1797, 0.8465, 0.1183, 0.1834, 0.8429, 0.5681, 0.8861, 0.6708, 0.9481,\n",
       "         0.1706, 0.5040, 0.0463, 0.0209, 0.4391, 0.9406, 0.7443, 0.3492, 0.1972,\n",
       "         0.1951, 0.3796, 0.2159, 0.9157, 0.7877, 0.3728, 0.8788, 0.2852, 0.9288,\n",
       "         0.3547, 0.9041, 0.1623, 0.4421, 0.5251, 0.3797, 0.8676, 0.0015, 0.7613,\n",
       "         0.4114, 0.6531, 0.7920, 0.4697, 0.9334, 0.1087, 0.0456, 0.7447, 0.0200,\n",
       "         0.1766]])"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1, config.n_hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFLf_AuGum30"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
